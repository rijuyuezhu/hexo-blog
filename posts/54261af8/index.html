<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com//css2?family=Lucida+Grande:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Tahoma:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Hiragino+Sans+GB:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Verdana:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Arial:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Microsoft+YaHei:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&family=Sans-serif:ital,wght@0,300;0,400;0,700;1,300;1,400;1,700&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"blog.rijuyuezhu.top","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.23.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeIn"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false,"trigger":"auto"}}</script><script src="/js/config.js" defer></script>

    <meta name="description" content="This article introduces the basic concepts of AI compilation, including its workflow, and its applications such as PyTorch, TVM, and MLIR.">
<meta property="og:type" content="article">
<meta property="og:title" content="AI Compilation Introduction">
<meta property="og:url" content="https://blog.rijuyuezhu.top/posts/54261af8/index.html">
<meta property="og:site_name" content="Rijuyuezhu&#39;s Blog">
<meta property="og:description" content="This article introduces the basic concepts of AI compilation, including its workflow, and its applications such as PyTorch, TVM, and MLIR.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://blog.rijuyuezhu.top/posts/54261af8/aicompiler.drawio.svg">
<meta property="og:image" content="https://blog.rijuyuezhu.top/posts/54261af8/tvm_overall_flow.svg">
<meta property="og:image" content="https://blog.rijuyuezhu.top/posts/54261af8/tvm_compile_rt.png">
<meta property="og:image" content="https://blog.rijuyuezhu.top/posts/54261af8/mlir_dialects.png">
<meta property="article:published_time" content="2025-03-13T06:30:44.000Z">
<meta property="article:modified_time" content="2025-03-14T02:22:29.175Z">
<meta property="article:author" content="Rijuyuezhu">
<meta property="article:tag" content="Artificial Intelligence">
<meta property="article:tag" content="Compilation">
<meta property="article:tag" content="PyTorch">
<meta property="article:tag" content="TVM">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.rijuyuezhu.top/posts/54261af8/aicompiler.drawio.svg">


<link rel="canonical" href="https://blog.rijuyuezhu.top/posts/54261af8/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://blog.rijuyuezhu.top/posts/54261af8/","path":"posts/54261af8/","title":"AI Compilation Introduction"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>AI Compilation Introduction | Rijuyuezhu's Blog</title>
  








  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous" defer></script>
<script src="/js/utils.js" defer></script><script src="/js/sidebar.js" defer></script><script src="/js/next-boot.js" defer></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous" defer></script>
<script src="/js/third-party/search/local-search.js" defer></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js" defer></script>



  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Rijuyuezhu's Blog</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Record every drop in my life</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="Searching..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#ai-compilation-introduction"><span class="nav-text">AI Compilation
Introduction</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#ai-compilation-designs"><span class="nav-text">AI Compilation Designs</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#great-articles"><span class="nav-text">Great Articles</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#pytorch-infrastructure"><span class="nav-text">PyTorch Infrastructure</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#torchscript"><span class="nav-text">TorchScript</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#torch-fx"><span class="nav-text">Torch FX</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#torch-compile-and-torch-dynamo"><span class="nav-text">Torch Compile and Torch
Dynamo</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#great-articles-1"><span class="nav-text">Great Articles</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#tvm-tensor-virtual-machine"><span class="nav-text">TVM (Tensor Virtual Machine)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#concepts"><span class="nav-text">Concepts</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#running-example"><span class="nav-text">Running Example</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#great-articles-2"><span class="nav-text">Great Articles</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#mlir-multi-level-intermediate-representation"><span class="nav-text">MLIR (Multi-Level
Intermediate Representation)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#concepts-1"><span class="nav-text">Concepts</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#great-articles-3"><span class="nav-text">Great Articles</span></a></li></ol></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Rijuyuezhu"
      src="/images/avatar.jpg">
  <p class="site-author-name" itemprop="name">Rijuyuezhu</p>
  <div class="site-description" itemprop="description">Knowledge and Practice!</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">47</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">15</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">26</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/rijuyuezhu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;rijuyuezhu" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:wr-huang@outlook.com" title="E-Mail → mailto:wr-huang@outlook.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://blog.rijuyuezhu.top/posts/54261af8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg">
      <meta itemprop="name" content="Rijuyuezhu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Rijuyuezhu's Blog">
      <meta itemprop="description" content="Knowledge and Practice!">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="AI Compilation Introduction | Rijuyuezhu's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          AI Compilation Introduction
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-03-13 14:30:44" itemprop="dateCreated datePublished" datetime="2025-03-13T14:30:44+08:00">2025-03-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Artificial-Intelligence/" itemprop="url" rel="index"><span itemprop="name">Artificial Intelligence</span></a>
        </span>
          , 
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Artificial-Intelligence/Compilation/" itemprop="url" rel="index"><span itemprop="name">Compilation</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>This article introduces the basic concepts of AI compilation,
including its workflow, and its applications such as PyTorch, TVM, and
MLIR.</p>
<span id="more"></span>
<h1 id="ai-compilation-introduction"><strong>AI Compilation
Introduction</strong></h1>
<h2 id="ai-compilation-designs">AI Compilation Designs</h2>
<p>AI Compilers transform a <em>computation graph</em> into low-level
code (e.g. LLVM-IR, SPIR-V, MLIR) which can be interpreted or further
compiled for a <em>target device</em>. An AI Compiler typically consists
of the following parts.</p>
<figure>
<img src="aicompiler.drawio.svg" width=100% />
<figcaption>
<p>
Figure 1: AI Compiler Routine
</p>
</figcaption>
</figure>
<p>There are three levels of optimization in AI compilers:</p>
<dl>
<dt>Graph-Level Optimization.</dt>
<dd>
<p>The computation graph is optimized by operating on the graph
structure, such as removing redundant nodes (operators), fusing nodes,
and applying graph-level transformations.</p>
</dd>
<dt>Operator-Level Optimization.</dt>
<dd>
<p>An operator can be optimized by applying transformations to the
for-loops, such as loop unrolling, loop tiling, and loop fusion.</p>
</dd>
<dt>ISA-Level Optimization.</dt>
<dd>
<p>The backend generates code that leverages special instructions on the
target device, such as SIMD instructions, tensor instructions, and other
hardware accelerator-specific instructions.</p>
</dd>
</dl>
<h3 id="great-articles">Great Articles</h3>
<ul>
<li>Awesome Tensor Compilers: <a
target="_blank" rel="noopener" href="https://github.com/merrymercy/awesome-tensor-compilers"
class="uri">https://github.com/merrymercy/awesome-tensor-compilers</a></li>
</ul>
<h2 id="pytorch-infrastructure">PyTorch Infrastructure</h2>
<p>By default, PyTorch uses its eager execution mode to describe a
model, where the computation graph is dynamically constructed and
executed, and is referred to as a <em>dynamic graph</em>.</p>
<p>PyTorch provides several ways to convert the dynamic graph to a
<em>static graph</em> for AI compilation.</p>
<h3 id="torchscript">TorchScript</h3>
<p><strong>TorchScript</strong> (deprecated) is a method to convert the
dynamic graph to a static graph using a Python-like language.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyCell</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyCell, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.linear = torch.nn.Linear(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, h</span>):</span><br><span class="line">        new_h = torch.tanh(<span class="variable language_">self</span>.linear(x) + h)</span><br><span class="line">        <span class="keyword">return</span> new_h, new_h</span><br><span class="line"></span><br><span class="line">my_cell = MyCell()</span><br><span class="line">x, h = torch.rand(<span class="number">3</span>, <span class="number">4</span>), torch.rand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;my_cell: \n&quot;</span>, my_cell, <span class="string">&quot;\n&quot;</span>, my_cell(x, h), <span class="string">&quot;\n&quot;</span>, my_cell.graph)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Way 1: tracing the model</span></span><br><span class="line">traced_cell = torch.jit.trace(my_cell, (x, h))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n\ntraced_cell: \n&quot;</span>, traced_cell, <span class="string">&quot;\n&quot;</span>, traced_cell(x, h), <span class="string">&quot;\n&quot;</span>, traced_cell.graph)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Way 2: scripting the model</span></span><br><span class="line">scripted_cell = torch.jit.script(my_cell)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n\nscripted_cell: \n&quot;</span>, scripted_cell, <span class="string">&quot;\n&quot;</span>, scripted_cell(x, h), <span class="string">&quot;\n&quot;</span>, scripted_cell.graph)</span><br></pre></td></tr></table></figure>
<p>This outputs</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">my_cell:</span><br><span class="line"> MyCell(</span><br><span class="line">  (linear): Linear(in_features=4, out_features=4, bias=True)</span><br><span class="line">)</span><br><span class="line"> (tensor([[0.0229, 0.3737, 0.6648, 0.7164],</span><br><span class="line">        [0.6495, 0.6735, 0.4847, 0.3583],</span><br><span class="line">        [0.2359, 0.4631, 0.9131, 0.4446]], grad_fn=&lt;TanhBackward0&gt;), tensor([[0.0229, 0.3737, 0.6648, 0.7164],</span><br><span class="line">        [0.6495, 0.6735, 0.4847, 0.3583],</span><br><span class="line">        [0.2359, 0.4631, 0.9131, 0.4446]], grad_fn=&lt;TanhBackward0&gt;))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">traced_cell:</span><br><span class="line"> MyCell(</span><br><span class="line">  original_name=MyCell</span><br><span class="line">  (linear): Linear(original_name=Linear)</span><br><span class="line">)</span><br><span class="line"> (tensor([[0.0229, 0.3737, 0.6648, 0.7164],</span><br><span class="line">        [0.6495, 0.6735, 0.4847, 0.3583],</span><br><span class="line">        [0.2359, 0.4631, 0.9131, 0.4446]], grad_fn=&lt;TanhBackward0&gt;), tensor([[0.0229, 0.3737, 0.6648, 0.7164],</span><br><span class="line">        [0.6495, 0.6735, 0.4847, 0.3583],</span><br><span class="line">        [0.2359, 0.4631, 0.9131, 0.4446]], grad_fn=&lt;TanhBackward0&gt;))</span><br><span class="line"> graph(%self.1 : __torch__.MyCell,</span><br><span class="line">      %x : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu),</span><br><span class="line">      %h : Float(3, 4, strides=[4, 1], requires_grad=0, device=cpu)):</span><br><span class="line">  %linear : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name=&quot;linear&quot;](%self.1)</span><br><span class="line">  %20 : Tensor = prim::CallMethod[name=&quot;forward&quot;](%linear, %x)</span><br><span class="line">  %11 : int = prim::Constant[value=1]() # /pwd/main.py:9:0</span><br><span class="line">  %12 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::add(%20, %h, %11) # /pwd/main.py:90</span><br><span class="line">  %13 : Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu) = aten::tanh(%12) # /pwd/main.py:9:0</span><br><span class="line">  %14 : (Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu), Float(3, 4, strides=[4, 1], requires_grad=1, device=cpu)) = prim::TupleConstruct(%13, %13)</span><br><span class="line">  return (%14)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">scripted_cell:</span><br><span class="line"> RecursiveScriptModule(</span><br><span class="line">  original_name=MyCell</span><br><span class="line">  (linear): RecursiveScriptModule(original_name=Linear)</span><br><span class="line">)</span><br><span class="line"> (tensor([[0.0229, 0.3737, 0.6648, 0.7164],</span><br><span class="line">        [0.6495, 0.6735, 0.4847, 0.3583],</span><br><span class="line">        [0.2359, 0.4631, 0.9131, 0.4446]], grad_fn=&lt;TanhBackward0&gt;), tensor([[0.0229, 0.3737, 0.6648, 0.7164],</span><br><span class="line">        [0.6495, 0.6735, 0.4847, 0.3583],</span><br><span class="line">        [0.2359, 0.4631, 0.9131, 0.4446]], grad_fn=&lt;TanhBackward0&gt;))</span><br><span class="line"> graph(%self : __torch__.___torch_mangle_3.MyCell,</span><br><span class="line">      %x.1 : Tensor,</span><br><span class="line">      %h.1 : Tensor):</span><br><span class="line">  %7 : int = prim::Constant[value=1]()</span><br><span class="line">  %linear : __torch__.torch.nn.modules.linear.___torch_mangle_2.Linear = prim::GetAttr[name=&quot;linear&quot;](%self)</span><br><span class="line">  %5 : Tensor = prim::CallMethod[name=&quot;forward&quot;](%linear, %x.1) # /pwd/main.py:9:27</span><br><span class="line">  %8 : Tensor = aten::add(%5, %h.1, %7) # /pwd/main.py:9:27</span><br><span class="line">  %new_h.1 : Tensor = aten::tanh(%8) # /pwd/main.py:9:16</span><br><span class="line">  %12 : (Tensor, Tensor) = prim::TupleConstruct(%new_h.1, %new_h.1)</span><br><span class="line">  return (%12)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li><p><strong>Trace</strong> (<code>torch.jit.trace</code>) is a way to
convert the dynamic graph to a static graph by tracing the model with a
set of inputs. However, some control flows cannot be traced. For
example,</p>
<pre><code>class MyDecisionGate(torch.nn.Module):
   def forward(self, x):
       if x.sum() &gt; 0:
           return x
       else:
           return -x</code></pre></li>
<li><p><strong>Script</strong> (<code>torch.jit.script</code>) is a way
to convert the dynamic graph to a static graph by using a Python-like
language. It can handle control flows, but it requires the model to be
written in a subset of Python.</p></li>
</ul>
<h3 id="torch-fx">Torch FX</h3>
<p><strong>Torch FX</strong> is a tool for modifying the computational
graph. Some optimizations, such as operator fusion, can be applied to
the graph using this tool. Also, Torch FX supports
<code>torch.fx.Graph</code>, which is a way to represent the computation
graph in a more flexible way (it is like a call graph!).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.fx</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModule</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.param = torch.nn.Parameter(torch.rand(<span class="number">3</span>, <span class="number">4</span>))</span><br><span class="line">        <span class="variable language_">self</span>.linear = torch.nn.Linear(<span class="number">4</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> torch.topk(</span><br><span class="line">            torch.<span class="built_in">sum</span>(<span class="variable language_">self</span>.linear(x + <span class="variable language_">self</span>.linear.weight).relu(), dim=-<span class="number">1</span>), <span class="number">3</span></span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">m = MyModule()</span><br><span class="line">gm = torch.fx.symbolic_trace(m)</span><br><span class="line"></span><br><span class="line">gm.graph.print_tabular()</span><br></pre></td></tr></table></figure>
<p>This outputs</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">opcode         name           target                                                   args                kwargs</span><br><span class="line">-------------  -------------  -------------------------------------------------------  ------------------  -----------</span><br><span class="line">placeholder    x              x                                                        ()                  &#123;&#125;</span><br><span class="line">get_attr       linear_weight  linear.weight                                            ()                  &#123;&#125;</span><br><span class="line">call_function  add            &lt;built-in function add&gt;                                  (x, linear_weight)  &#123;&#125;</span><br><span class="line">call_module    linear         linear                                                   (add,)              &#123;&#125;</span><br><span class="line">call_method    relu           relu                                                     (linear,)           &#123;&#125;</span><br><span class="line">call_function  sum_1          &lt;built-in method sum of type object at 0x7dc9e439af60&gt;   (relu,)             &#123;&#x27;dim&#x27;: -1&#125;</span><br><span class="line">call_function  topk           &lt;built-in method topk of type object at 0x7dc9e439af60&gt;  (sum_1, 3)          &#123;&#125;</span><br><span class="line">output         output         output                                                   (topk,)             &#123;&#125;</span><br></pre></td></tr></table></figure>
<h3 id="torch-compile-and-torch-dynamo">Torch Compile and Torch
Dynamo</h3>
<ul>
<li><p>Torch Compile (<code>torch.compile</code>) provides a high-level
API to compile PyTorch models into static graphs just in time. It uses
Torch Dynamo as the backend to generate the static graph.</p></li>
<li><p>Torch Dynamo, different from TorchScript and Torch FX, uses JIT
to compile the <em>bytecode</em> of the model to a static graph. When
some operations in the computational graph generations are hard to
compile without further information, Torch Dynamo could break the whole
generation into several smaller graphs and compile them one by one,
leaving the barrier unchanged.</p></li>
<li><p>Torch Dynamo provides a way to compile the model to Torch FX
Graph, under the circumstance that NO barriers (as mentioned above) are
met.</p></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line"><span class="meta">@torch.compile</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyCell</span>(torch.nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyCell, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.linear = torch.nn.Linear(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, h</span>):</span><br><span class="line">        new_h = torch.tanh(<span class="variable language_">self</span>.linear(x) + h)</span><br><span class="line">        <span class="keyword">return</span> new_h, new_h</span><br><span class="line"></span><br><span class="line">my_cell = MyCell()</span><br><span class="line">x, h = torch.rand(<span class="number">3</span>, <span class="number">4</span>), torch.rand(<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(my_cell(x, h))</span><br></pre></td></tr></table></figure>
<h3 id="great-articles-1">Great Articles</h3>
<ul>
<li>PyTorch Official Tutorial: <a target="_blank" rel="noopener" href="https://pytorch.org/tutorials/"
class="uri">https://pytorch.org/tutorials/</a></li>
</ul>
<h2 id="tvm-tensor-virtual-machine">TVM (Tensor Virtual Machine)</h2>
<h3 id="concepts">Concepts</h3>
<p>TVM compiles deep learning models (Computation Graph) into various
hardware device instruction sets (with minimal runtime). It receives
<strong>models</strong> from PyTorch, TensorFlow, ONNX etc., and
compiles them for various target <strong>devices</strong>.</p>
<figure>
<img src="tvm_overall_flow.svg" width=70% />
<figcaption>
<p>
Figure 2: TVM working flow
</p>
</figcaption>
</figure>
<figure>
<img src="tvm_compile_rt.png" width=70% />
<figcaption>
<p>
Figure 3: TVM compilation and runtime
</p>
</figcaption>
</figure>
<h3 id="running-example">Running Example</h3>
<p>Given a simple MLP model (here we use TVM frontend to describe the
model; in practice, one can use PyTorch or other frameworks to define
it):<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tvm</span><br><span class="line"><span class="keyword">from</span> tvm <span class="keyword">import</span> relax</span><br><span class="line"><span class="keyword">from</span> tvm.relax.frontend <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MLPModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MLPModel, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(<span class="number">784</span>, <span class="number">256</span>)</span><br><span class="line">        <span class="variable language_">self</span>.relu1 = nn.ReLU()</span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">256</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = <span class="variable language_">self</span>.fc1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.relu1(x)</span><br><span class="line">        x = <span class="variable language_">self</span>.fc2(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>Then we manually instruct TVM to generate an <em>IRModule</em>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">mod, param_spec = MLPModel().export_tvm(</span><br><span class="line">    spec=&#123;<span class="string">&quot;forward&quot;</span>: &#123;<span class="string">&quot;x&quot;</span>: nn.spec.Tensor((<span class="number">1</span>, <span class="number">784</span>), <span class="string">&quot;float32&quot;</span>)&#125;&#125;</span><br><span class="line">)</span><br><span class="line">mod.show()</span><br></pre></td></tr></table></figure>
<p>The module is in the following form, showing the entire computation
graph:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from tvm.script import ir as I</span></span><br><span class="line"><span class="comment"># from tvm.script import relax as R</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@I.ir_module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Module</span>:</span><br><span class="line"><span class="meta">    @R.function</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x: R.Tensor(<span class="params">(<span class="params"><span class="number">1</span>, <span class="number">784</span></span>), dtype=<span class="string">&quot;float32&quot;</span></span>), fc1_weight: R.Tensor(<span class="params">(<span class="params"><span class="number">256</span>, <span class="number">784</span></span>), dtype=<span class="string">&quot;float32&quot;</span></span>), fc1_bias: R.Tensor(<span class="params">(<span class="params"><span class="number">256</span>,</span>), dtype=<span class="string">&quot;float32&quot;</span></span>), fc2_weight: R.Tensor(<span class="params">(<span class="params"><span class="number">10</span>, <span class="number">256</span></span>), dtype=<span class="string">&quot;float32&quot;</span></span>), fc2_bias: R.Tensor(<span class="params">(<span class="params"><span class="number">10</span>,</span>), dtype=<span class="string">&quot;float32&quot;</span></span>)</span>) -&gt; R.Tensor((<span class="number">1</span>, <span class="number">10</span>), dtype=<span class="string">&quot;float32&quot;</span>):</span><br><span class="line">        R.func_attr(&#123;<span class="string">&quot;num_input&quot;</span>: <span class="number">1</span>&#125;)</span><br><span class="line">        <span class="keyword">with</span> R.dataflow():</span><br><span class="line">            permute_dims: R.Tensor((<span class="number">784</span>, <span class="number">256</span>), dtype=<span class="string">&quot;float32&quot;</span>) = R.permute_dims(fc1_weight, axes=<span class="literal">None</span>)</span><br><span class="line">            matmul: R.Tensor((<span class="number">1</span>, <span class="number">256</span>), dtype=<span class="string">&quot;float32&quot;</span>) = R.matmul(x, permute_dims, out_dtype=<span class="string">&quot;void&quot;</span>)</span><br><span class="line">            add: R.Tensor((<span class="number">1</span>, <span class="number">256</span>), dtype=<span class="string">&quot;float32&quot;</span>) = R.add(matmul, fc1_bias)</span><br><span class="line">            relu: R.Tensor((<span class="number">1</span>, <span class="number">256</span>), dtype=<span class="string">&quot;float32&quot;</span>) = R.nn.relu(add)</span><br><span class="line">            permute_dims1: R.Tensor((<span class="number">256</span>, <span class="number">10</span>), dtype=<span class="string">&quot;float32&quot;</span>) = R.permute_dims(fc2_weight, axes=<span class="literal">None</span>)</span><br><span class="line">            matmul1: R.Tensor((<span class="number">1</span>, <span class="number">10</span>), dtype=<span class="string">&quot;float32&quot;</span>) = R.matmul(relu, permute_dims1, out_dtype=<span class="string">&quot;void&quot;</span>)</span><br><span class="line">            add1: R.Tensor((<span class="number">1</span>, <span class="number">10</span>), dtype=<span class="string">&quot;float32&quot;</span>) = R.add(matmul1, fc2_bias)</span><br><span class="line">            gv: R.Tensor((<span class="number">1</span>, <span class="number">10</span>), dtype=<span class="string">&quot;float32&quot;</span>) = add1</span><br><span class="line">            R.output(gv)</span><br><span class="line">        <span class="keyword">return</span> gv</span><br></pre></td></tr></table></figure>
<p>Then optimization passes are applied to the IRModule in a pipelined
manner. A library dispatch can be applied, and auto-tuning can be used
to find the best configuration for the target device. For example, the
following example fuses <code>nn.Linear</code> and <code>nn.ReLU</code>
and rewrites them into a <code>call_dps_packed</code> function for
CUBLAS library.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Import cublas pattern</span></span><br><span class="line"><span class="keyword">import</span> tvm.relax.backend.cuda.cublas <span class="keyword">as</span> _cublas</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define a new pass for CUBLAS dispatch</span></span><br><span class="line"><span class="meta">@tvm.transform.module_pass(<span class="params">opt_level=<span class="number">0</span>, name=<span class="string">&quot;CublasDispatch&quot;</span></span>)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CublasDispatch</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">transform_module</span>(<span class="params">self, mod: IRModule, _ctx: tvm.transform.PassContext</span>) -&gt; IRModule:</span><br><span class="line">        <span class="comment"># Get interested patterns</span></span><br><span class="line">        patterns = [relax.backend.get_pattern(<span class="string">&quot;cublas.matmul_transposed_bias_relu&quot;</span>)]</span><br><span class="line">        <span class="comment"># Note in real-world cases, we usually get all patterns</span></span><br><span class="line">        <span class="comment"># patterns = relax.backend.get_patterns_with_prefix(&quot;cublas&quot;)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Fuse ops by patterns and then run codegen</span></span><br><span class="line">        mod = relax.transform.FuseOpsByPattern(patterns, annotate_codegen=<span class="literal">True</span>)(mod)</span><br><span class="line">        mod = relax.transform.RunCodegen()(mod)</span><br><span class="line">        <span class="keyword">return</span> mod</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mod = CublasDispatch()(mod)</span><br><span class="line">mod.show()</span><br></pre></td></tr></table></figure>
<p>And the IRModule is transformed into the following form:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># from tvm.script import ir as I</span></span><br><span class="line"><span class="comment"># from tvm.script import relax as R</span></span><br><span class="line"></span><br><span class="line"><span class="meta">@I.ir_module</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Module</span>:</span><br><span class="line">    I.module_attrs(&#123;<span class="string">&quot;external_mods&quot;</span>: [metadata[<span class="string">&quot;runtime.Module&quot;</span>][<span class="number">0</span>]]&#125;)</span><br><span class="line"><span class="meta">    @R.function</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">x: R.Tensor(<span class="params">(<span class="params"><span class="number">1</span>, <span class="number">784</span></span>), dtype=<span class="string">&quot;float32&quot;</span></span>), fc1_weight: R.Tensor(<span class="params">(<span class="params"><span class="number">256</span>, <span class="number">784</span></span>), dtype=<span class="string">&quot;float32&quot;</span></span>), fc1_bias: R.Tensor(<span class="params">(<span class="params"><span class="number">256</span>,</span>), dtype=<span class="string">&quot;float32&quot;</span></span>), fc2_weight: R.Tensor(<span class="params">(<span class="params"><span class="number">10</span>, <span class="number">256</span></span>), dtype=<span class="string">&quot;float32&quot;</span></span>)</span>) -&gt; R.Tensor((<span class="number">1</span>, <span class="number">10</span>), dtype=<span class="string">&quot;float32&quot;</span>):</span><br><span class="line">        R.func_attr(&#123;<span class="string">&quot;num_input&quot;</span>: <span class="number">1</span>&#125;)</span><br><span class="line">        <span class="keyword">with</span> R.dataflow():</span><br><span class="line">            lv = R.call_dps_packed(<span class="string">&quot;fused_relax_permute_dims_relax_matmul_relax_add_relax_nn_relu_cublas&quot;</span>, (fc1_weight, x, fc1_bias), out_sinfo=R.Tensor((<span class="number">1</span>, <span class="number">256</span>), dtype=<span class="string">&quot;float32&quot;</span>))</span><br><span class="line">            permute_dims1: R.Tensor((<span class="number">256</span>, <span class="number">10</span>), dtype=<span class="string">&quot;float32&quot;</span>) = R.permute_dims(fc2_weight, axes=<span class="literal">None</span>)</span><br><span class="line">            matmul1: R.Tensor((<span class="number">1</span>, <span class="number">10</span>), dtype=<span class="string">&quot;float32&quot;</span>) = R.matmul(lv, permute_dims1, out_dtype=<span class="string">&quot;void&quot;</span>)</span><br><span class="line">            gv: R.Tensor((<span class="number">1</span>, <span class="number">10</span>), dtype=<span class="string">&quot;float32&quot;</span>) = matmul1</span><br><span class="line">            R.output(gv)</span><br><span class="line">        <span class="keyword">return</span> gv</span><br><span class="line"></span><br><span class="line"><span class="comment"># Metadata omitted. Use show_meta=True in script() method to show it.</span></span><br></pre></td></tr></table></figure>
<p>Additionally, auto-tuning (using a machine learning algorithm to find
optimal solutions) is available:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">device = tvm.cuda(<span class="number">0</span>)</span><br><span class="line">target = tvm.target.Target.from_device(device)</span><br><span class="line">trials = <span class="number">2000</span></span><br><span class="line"><span class="keyword">with</span> target, tempfile.TemporaryDirectory() <span class="keyword">as</span> tmp_dir:</span><br><span class="line">    mod = tvm.ir.transform.Sequential(</span><br><span class="line">        [</span><br><span class="line">            relax.get_pipeline(<span class="string">&quot;zero&quot;</span>),</span><br><span class="line">            relax.transform.MetaScheduleTuneTIR(work_dir=tmp_dir, max_trials_global=trials),</span><br><span class="line">            relax.transform.MetaScheduleApplyDatabase(work_dir=tmp_dir),</span><br><span class="line">        ]</span><br><span class="line">    )(mod)</span><br><span class="line"></span><br><span class="line">mod.show()</span><br></pre></td></tr></table></figure>
<p>Finally, after extensive optimization, the compilation continues and
the final code is generated. A TVM runtime supports loads the code and
runs it on the target device.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Generate optimized code (which can be saved and loaded)</span></span><br><span class="line">target = tvm.target.Target(<span class="string">&quot;llvm&quot;</span>)</span><br><span class="line">ex = relax.build(mod, target)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Run VM (at the device side)</span></span><br><span class="line">device = tvm.cpu()</span><br><span class="line">vm = relax.VirtualMachine(ex, device)</span><br><span class="line"></span><br><span class="line">data = np.random.rand(<span class="number">1</span>, <span class="number">784</span>).astype(<span class="string">&quot;float32&quot;</span>)</span><br><span class="line">tvm_data = tvm.nd.array(data, device=device)</span><br><span class="line">params = [np.random.rand(*param.shape).astype(<span class="string">&quot;float32&quot;</span>) <span class="keyword">for</span> _, param <span class="keyword">in</span> param_spec]</span><br><span class="line">params = [tvm.nd.array(param, device=device) <span class="keyword">for</span> param <span class="keyword">in</span> params]</span><br><span class="line"><span class="built_in">print</span>(vm[<span class="string">&quot;forward&quot;</span>](tvm_data, *params).numpy())</span><br></pre></td></tr></table></figure>
<h3 id="great-articles-2">Great Articles</h3>
<ul>
<li><p>TVM official documentation: <a target="_blank" rel="noopener" href="https://tvm.apache.org/docs"
class="uri">https://tvm.apache.org/docs</a></p></li>
<li><p>Tutorial of TVM (in Chinese): <a
target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/532873577"
class="uri">https://zhuanlan.zhihu.com/p/532873577</a></p></li>
</ul>
<h2 id="mlir-multi-level-intermediate-representation">MLIR (Multi-Level
Intermediate Representation)</h2>
<h3 id="concepts-1">Concepts</h3>
<p>To support DSLs (including those for AI compilation) and represent
many application/device-specific objects, a single centralized IR - LLVM
IR</p>
<ul>
<li>is insufficient. MLIR is designed to address this problem. It has a
<strong>discrete</strong>, <strong>hierarchical</strong> and
<strong>extensible</strong> definition, where many <em>dialects</em> can
be defined to represent different levels of abstraction and different
domains.</li>
</ul>
<figure>
<img src="mlir_dialects.png" width=100% />
<figcaption>
<p>
Figure 4: MLIR Dialects
</p>
</figcaption>
</figure>
<h3 id="great-articles-3">Great Articles</h3>
<ul>
<li><p>MLIR learning path (in Chinese): <a
target="_blank" rel="noopener" href="https://www.zhihu.com/question/435109274"
class="uri">https://www.zhihu.com/question/435109274</a></p></li>
<li><p>MLIR inspiration (in Chinese): <a
target="_blank" rel="noopener" href="https://www.lei.chat/zh/posts/compilers-and-irs-llvm-ir-spirv-and-mlir"
class="uri">https://www.lei.chat/zh/posts/compilers-and-irs-llvm-ir-spirv-and-mlir</a></p></li>
<li><p>How TVM is different from MLIR: <a
target="_blank" rel="noopener" href="https://stackoverflow.com/questions/65288033/how-tvm-is-different-from-mlir"
class="uri">https://stackoverflow.com/questions/65288033/how-tvm-is-different-from-mlir</a></p></li>
</ul>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Example from <a target="_blank" rel="noopener" href="https://tvm.apache.org/docs/"
class="uri">https://tvm.apache.org/docs/</a><a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

    </div>

    
    
    

    <footer class="post-footer">
          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>Post author:  </strong>Rijuyuezhu
  </li>
  <li class="post-copyright-link">
      <strong>Post link: </strong>
      <a href="https://blog.rijuyuezhu.top/posts/54261af8/" title="AI Compilation Introduction">https://blog.rijuyuezhu.top/posts/54261af8/</a>
  </li>
  <li class="post-copyright-license">
      <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <a href="https://creativecommons.org/licenses/by/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY</a> unless stating additionally.
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/Artificial-Intelligence/" rel="tag"># Artificial Intelligence</a>
              <a href="/tags/Compilation/" rel="tag"># Compilation</a>
              <a href="/tags/PyTorch/" rel="tag"># PyTorch</a>
              <a href="/tags/TVM/" rel="tag"># TVM</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/posts/3296c668/" rel="prev" title="Install mailmaster via distrobox on other Linux distributions">
                  <i class="fa fa-angle-left"></i> Install mailmaster via distrobox on other Linux distributions
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/posts/2e93e0b4/" rel="next" title="SGLang Meets Deepseek">
                  SGLang Meets Deepseek <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Rijuyuezhu</span>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>
<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '64px',
  right: '32px',
  left: 'unset',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>
<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"rijuyuezhu/hexo-blog-comments","issue_term":"pathname","theme":"github-light"}</script>
<script src="/js/third-party/comments/utterances.js" defer></script>

</body>
</html>
